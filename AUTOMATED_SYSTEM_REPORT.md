# ü§ñ Automated Cloud Workflow & Data Systems Report

## 1. Workflow Architecture Overview

Your system uses a **Hybrid Cloud Architecture** where GitHub Actions acts as the "Commander" and the Hetzner VPS acts as the "Executor".

| Workflow Name | **Type** | **Role** | **Schedule (Cairo Time)** | **Execution Location** |
| :--- | :--- | :--- | :--- | :--- |
| **Enterprise Data Update** | `Scheduled CRON` | **Commander** | Every 5 mins (Prices)<br>6:00 PM (Daily Sync)<br>7:00 PM (Funds)<br>8:00 PM (AI Data) | GitHub Cloud ‚Üí Triggers Hetzner |
| **Internal Scheduler** | `Daemon Service` | **Executor** | Continuous Loop | Hetzner VPS (Local) |
| **Production Watchdog** | `Health Monitor` | **Auditor** | Every 6 hours | GitHub Cloud |

---

## 2. Detailed Data Update Specifications

The following tables detail exactly **what** data is updated, **where** it goes (Database Table), and **how** it is sourced.

### üÖ∞Ô∏è Intraday Stock Data (Type: `Real-Time`)
**Frequency:** Every 5 Minutes (Market Hours)
**Source:** `yfinance` (Saudi) & `StockAnalysis` (Egypt)

| Field Name | Description | Database Table |
| :--- | :--- | :--- |
| `last_price` | Current trading price | `market_tickers` |
| `change` | Value change from open | `market_tickers` |
| `change_percent` | Percentage change | `market_tickers` |
| `volume` | Shares traded today | `market_tickers` |
| `high` / `low` | Daily High/Low peaks | `market_tickers` |
| `last_updated` | Timestamp of update | `market_tickers` |

### üÖ±Ô∏è End-of-Day (EOD) History (Type: `Historical`)
**Frequency:** Daily at 6:00 PM
**Source:** `yfinance` & `ingest_stockanalysis.py`

| Field Name | Description | Database Table |
| :--- | :--- | :--- |
| `close` | Official closing price | `ohlc_data` |
| `open` | Official opening price | `ohlc_data` |
| `volume` | Total daily volume | `ohlc_data` |
| `pattern_detected` | AI Candle Pattern (optional) | `tech_analysis` |
| `rsi_14` | Relative Strength Index | `tech_analysis` |

### ¬©Ô∏è Mutual Funds Intelligence (Type: `Deep Extraction`)
**Frequency:** Daily at 7:00 PM
**Source:** `scrape_mubasher.py` (Mubasher Deep Extract)

| Field Name | Description | Database Table |
| :--- | :--- | :--- |
| `latest_nav` | Net Asset Value (Price) | `mutual_funds` |
| `ytd_return` | Year-to-Date Profit % | `mutual_funds` |
| `manager_name` | Fund Manager Name | `mutual_funds` |
| `last_update_date` | Date of NAV publication | `mutual_funds` |
| `nav_history` | Historical NAV points | `nav_history` |

### üá© Fundamental AI Knowledge (Type: `Ingestion`)
**Frequency:** Daily at 8:00 PM
**Source:** `yahooquery` & `StockAnalysis` HTML

| Field Name | Description | Database Table |
| :--- | :--- | :--- |
| `pe_ratio` | Price-to-Earnings Ratio | `company_profiles` |
| `total_revenue` | Annual/Quarterly Revenue | `financial_statements` |
| `net_income` | Net Profit | `financial_statements` |
| `description` | AI Company Summary | `company_profiles` |
| `sector_name` | Corrected Sector | `market_tickers` |

---

## 3. Workflow Control & Safety

### üîí The "Nuclear" Safety Protocol
Your system includes a specialized safety workflow to prevent data corruption is called the **"No-Overwrite Policy"**:
*   **Protocol**: `INSERT ON CONFLICT DO NOTHING`
*   **Effect**: The system never deletes old history. It only *appends* new data or *updates* current prices. This ensures your 19.2M+ datapoint reservoir remains intact even if a scraper fails.

### üîç Error Handling
*   **Watchdog**: If the API returns anything other than `200 OK`, GitHub Actions sends a **Discord Alert** immediately.
*   **Retries**: The workflow attempts 4 exponential backoff retries (10s, 30s, 60s, 120s) before alerting you.

---

**Generated by Antigravity Chief Expert**
*Verified against Production Config v1.0.5*
